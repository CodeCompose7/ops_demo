from datetime import datetime
from pathlib import Path

import joblib
import pandas as pd
from sklearn.model_selection import train_test_split


class IrisMLPipeline:
    """ê°„ë‹¨í•˜ì§€ë§Œ ì™„ì „í•œ ML íŒŒì´í”„ë¼ì¸"""

    def preprocess_data(self, X):
        """Iris ë°ì´í„°ì…‹ ì „ì²˜ë¦¬: ì´ìƒì¹˜ íƒì§€ ë° ì„ íƒì  ìŠ¤ì¼€ì¼ë§"""
        # DataFrameìœ¼ë¡œ ë³€í™˜ (ì´ìƒì¹˜ íƒì§€ìš©)
        df = pd.DataFrame(
            X,
            columns=[
                "sepal_length",
                "sepal_width",
                "petal_length",
                "petal_width",
            ],
        )

        # ì´ìƒì¹˜ íƒì§€ (IQR ë°©ë²•)
        print("  â†’ ì´ìƒì¹˜ íƒì§€ ì¤‘...")
        Q1 = df.quantile(0.25)
        Q3 = df.quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        # ì´ìƒì¹˜ê°€ ìˆëŠ” í–‰ ì°¾ê¸°
        outliers = ((df < lower_bound) | (df > upper_bound)).any(axis=1)
        outlier_count = outliers.sum()

        if outlier_count > 0:
            print(
                f"  â†’ ì´ìƒì¹˜ {outlier_count}ê°œ ë°œê²¬ "
                "(ì œê±°í•˜ì§€ ì•ŠìŒ - Iris ë°ì´í„°ëŠ” ì •ìƒ ë²”ìœ„)"
            )
        else:
            print("  â†’ ì´ìƒì¹˜ ì—†ìŒ")

        # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ (ì„ íƒì‚¬í•­ - RandomForestëŠ” ìŠ¤ì¼€ì¼ë§ì´ í•„ìš” ì—†ì§€ë§Œ ì¼ë°˜ì ì¸ íŒŒì´í”„ë¼ì¸)
        # ì£¼ì„ ì²˜ë¦¬: RandomForestëŠ” ìŠ¤ì¼€ì¼ë§ì´ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ìƒëµ
        # scaler = StandardScaler()
        # X_scaled = scaler.fit_transform(X)
        # print("  â†’ íŠ¹ì„± ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ (StandardScaler)")

        # Iris ë°ì´í„°ëŠ” ì´ë¯¸ ì •ê·œí™”ê°€ ì˜ ë˜ì–´ìˆìœ¼ë¯€ë¡œ ìŠ¤ì¼€ì¼ë§ ìƒëµ
        print("  â†’ ì „ì²˜ë¦¬ ì™„ë£Œ (Iris ë°ì´í„°ëŠ” ì¶”ê°€ ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”)")

        return X

    def data_pipeline(self):
        """ë°ì´í„° íŒŒì´í”„ë¼ì¸: ìˆ˜ì§‘ â†’ ê²€ì¦ â†’ ì „ì²˜ë¦¬ â†’ ë¶„í• """

        # ë°ì´í„° ìˆ˜ì§‘ (sklearn ë‚´ì¥ ë°ì´í„°ì…‹)
        from sklearn.datasets import load_iris

        iris = load_iris()
        X, y = iris.data, iris.target

        print("  â†’ ë°ì´í„° ìˆ˜ì§‘ (Iris dataset)")
        print(f"  â†’ ë°ì´í„° ê²€ì¦: {X.shape[0]}ê°œ ìƒ˜í”Œ, {X.shape[1]}ê°œ íŠ¹ì„±")
        assert X.shape[0] > 0, "ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
        assert not pd.DataFrame(X).isnull().any().any(), "ê²°ì¸¡ì¹˜ ë°œê²¬"

        # ì „ì²˜ë¦¬
        print("  â†’ ë°ì´í„° ì „ì²˜ë¦¬")
        X = self.preprocess_data(X)

        # ë°ì´í„° ë¶„í• 
        print("  â†’ ë°ì´í„° ë¶„í•  (Train: 80%, Test: 20%)")
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        print(f"     Train: {X_train.shape[0]}ê°œ, Test: {X_test.shape[0]}ê°œ")
        return X_train, X_test, y_train, y_test

    def training_pipeline(self, X_train, y_train):
        """í›ˆë ¨ íŒŒì´í”„ë¼ì¸"""
        from sklearn.ensemble import RandomForestClassifier

        print("  â†’ ëª¨ë¸ í›ˆë ¨ (RandomForestClassifier)")

        model = RandomForestClassifier(
            n_estimators=100,
            max_depth=5,
            random_state=42,
            n_jobs=-1,  # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©
        )

        print("  â†’ í•™ìŠµ ì‹œì‘...")
        model.fit(X_train, y_train)
        print("  â†’ í•™ìŠµ ì™„ë£Œ!")

        return model

    def evaluate_model(self, model, X_test, y_test):
        """ëª¨ë¸ í‰ê°€"""
        from sklearn.metrics import accuracy_score, f1_score

        y_pred = model.predict(X_test)

        accuracy = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred, average="weighted")

        print(f"  â†’ Accuracy: {accuracy:.4f}")
        print(f"  â†’ F1 Score: {f1:.4f}")

        # ëª¨ë¸ ê²€ì¦
        if accuracy < 0.85:
            print("  âš ï¸  ê²½ê³ : ì •í™•ë„ê°€ 85% ë¯¸ë§Œ!")
            print("  â†’ ì¬í›ˆë ¨ ë˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • í•„ìš”")
        else:
            print("  âœ… ëª¨ë¸ ê²€ì¦ í†µê³¼ (ì •í™•ë„ >= 85%)")

        return {"accuracy": accuracy, "f1_score": f1}

    def save_model(self, model, metrics):
        """ëª¨ë¸ + ë©”íƒ€ë°ì´í„° íŒ¨í‚¤ì§•"""

        model_artifact = {
            "model": model,
            "version": datetime.now().strftime("v%Y%m%d-%H%M%S"),
            "metrics": metrics,
            "feature_names": [
                "sepal_length",
                "sepal_width",
                "petal_length",
                "petal_width",
            ],
            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "target_names": ["setosa", "versicolor", "virginica"],
            "framework": "scikit-learn",
        }

        # models ë””ë ‰í† ë¦¬ ìƒì„±
        model_dir = Path("models")
        model_dir.mkdir(exist_ok=True)

        # ì €ì¥
        model_path = model_dir / "model.pkl"
        joblib.dump(model_artifact, model_path)

        print(f"  â†’ ëª¨ë¸ ë²„ì „: {model_artifact['version']}")
        print(f"  â†’ ì €ì¥ ê²½ë¡œ: {model_path}")

    def run_pipeline(self):
        print("=" * 60)
        print("ML Pipeline ì‹œì‘")
        print("=" * 60)

        # 1. Data Pipeline
        print("\n[1/4] ğŸ“Š Data Pipeline")
        X_train, X_test, y_train, y_test = self.data_pipeline()

        # 2. Training Pipeline
        print("\n[2/4] ğŸ¤– Training Pipeline")
        model = self.training_pipeline(X_train, y_train)

        # 3. Evaluation
        print("\n[3/4] ğŸ“ˆ Model Evaluation")
        metrics = self.evaluate_model(model, X_test, y_test)

        # 4. Serving Pipeline
        print("\n[4/4] ğŸ’¾ Serving Pipeline - ëª¨ë¸ ì €ì¥")
        self.save_model(model, metrics)

        print("\nâœ… Pipeline ì™„ë£Œ!")
        print("=" * 60)

        return model, metrics


if __name__ == "__main__":
    pipeline = IrisMLPipeline()
    pipeline.run_pipeline()
