import argparse
import os
from datetime import datetime
from pathlib import Path

import joblib
import mlflow
import mlflow.sklearn
import pandas as pd
from sklearn.model_selection import train_test_split


class IrisMLPipelineWithMLflow:
    """MLflow ì¶”ì ì´ í¬í•¨ëœ ML íŒŒì´í”„ë¼ì¸"""

    def __init__(self):
        """MLflow ì‹¤í—˜ ì„¤ì •"""
        # MLflow Tracking URI ì„¤ì • (Remote Tracking Server ì‚¬ìš©)
        tracking_uri = os.getenv("MLFLOW_TRACKING_URI", "http://mlflow-service:5000")
        mlflow.set_tracking_uri(tracking_uri)
        print(f"  â†’ MLflow Tracking URI: {tracking_uri}")
        
        mlflow.set_experiment("iris-classification")

    def preprocess_data(self, X):
        """Iris ë°ì´í„°ì…‹ ì „ì²˜ë¦¬: ì´ìƒì¹˜ íƒì§€ ë° ì„ íƒì  ìŠ¤ì¼€ì¼ë§"""
        # DataFrameìœ¼ë¡œ ë³€í™˜ (ì´ìƒì¹˜ íƒì§€ìš©)
        df = pd.DataFrame(
            X,
            columns=[
                "sepal_length",
                "sepal_width",
                "petal_length",
                "petal_width",
            ],
        )

        # ì´ìƒì¹˜ íƒì§€ (IQR ë°©ë²•)
        print("  â†’ ì´ìƒì¹˜ íƒì§€ ì¤‘...")
        Q1 = df.quantile(0.25)
        Q3 = df.quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        # ì´ìƒì¹˜ê°€ ìˆëŠ” í–‰ ì°¾ê¸°
        outliers = ((df < lower_bound) | (df > upper_bound)).any(axis=1)
        outlier_count = outliers.sum()

        if outlier_count > 0:
            print(
                f"  â†’ ì´ìƒì¹˜ {outlier_count}ê°œ ë°œê²¬ "
                "(ì œê±°í•˜ì§€ ì•ŠìŒ - Iris ë°ì´í„°ëŠ” ì •ìƒ ë²”ìœ„)"
            )
        else:
            print("  â†’ ì´ìƒì¹˜ ì—†ìŒ")

        # Iris ë°ì´í„°ëŠ” ì´ë¯¸ ì •ê·œí™”ê°€ ì˜ ë˜ì–´ìˆìœ¼ë¯€ë¡œ ìŠ¤ì¼€ì¼ë§ ìƒëµ
        print("  â†’ ì „ì²˜ë¦¬ ì™„ë£Œ (Iris ë°ì´í„°ëŠ” ì¶”ê°€ ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”)")

        return X

    def data_pipeline(self):
        """ë°ì´í„° íŒŒì´í”„ë¼ì¸: ìˆ˜ì§‘ â†’ ê²€ì¦ â†’ ì „ì²˜ë¦¬ â†’ ë¶„í• """

        # ë°ì´í„° ìˆ˜ì§‘ (sklearn ë‚´ì¥ ë°ì´í„°ì…‹)
        from sklearn.datasets import load_iris

        iris = load_iris()
        X, y = iris.data, iris.target

        print("  â†’ ë°ì´í„° ìˆ˜ì§‘ (Iris dataset)")
        print(f"  â†’ ë°ì´í„° ê²€ì¦: {X.shape[0]}ê°œ ìƒ˜í”Œ, {X.shape[1]}ê°œ íŠ¹ì„±")
        assert X.shape[0] > 0, "ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
        assert not pd.DataFrame(X).isnull().any().any(), "ê²°ì¸¡ì¹˜ ë°œê²¬"

        # ì „ì²˜ë¦¬
        print("  â†’ ë°ì´í„° ì „ì²˜ë¦¬")
        X = self.preprocess_data(X)

        # ë°ì´í„° ë¶„í• 
        print("  â†’ ë°ì´í„° ë¶„í•  (Train: 80%, Test: 20%)")
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        print(f"     Train: {X_train.shape[0]}ê°œ, Test: {X_test.shape[0]}ê°œ")
        return X_train, X_test, y_train, y_test

    def training_pipeline_with_tracking(
        self, X_train, y_train, n_estimators=100, max_depth=5
    ):
        """MLflow ì¶”ì ì´ í¬í•¨ëœ í›ˆë ¨ íŒŒì´í”„ë¼ì¸"""
        from sklearn.ensemble import RandomForestClassifier

        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ì˜
        params = {
            "n_estimators": n_estimators,
            "max_depth": max_depth,
            "random_state": 42,
            "n_jobs": -1,
        }

        # MLflowì— íŒŒë¼ë¯¸í„° ê¸°ë¡
        mlflow.log_params(params)

        print("  â†’ ëª¨ë¸ í›ˆë ¨ (RandomForestClassifier)")
        print(f"  â†’ í•˜ì´í¼íŒŒë¼ë¯¸í„°: {params}")

        model = RandomForestClassifier(**params)
        print("  â†’ í•™ìŠµ ì‹œì‘...")
        model.fit(X_train, y_train)
        print("  â†’ í•™ìŠµ ì™„ë£Œ! (MLflowì— íŒŒë¼ë¯¸í„° ê¸°ë¡ë¨)")

        return model, params

    def evaluate_model_with_tracking(self, model, X_test, y_test):
        """MLflow ì¶”ì ì´ í¬í•¨ëœ ëª¨ë¸ í‰ê°€"""
        from sklearn.metrics import (
            accuracy_score,
            f1_score,
            precision_score,
            recall_score,
        )

        y_pred = model.predict(X_test)

        # ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = {
            "accuracy": accuracy_score(y_test, y_pred),
            "f1_score": f1_score(y_test, y_pred, average="weighted"),
            "precision": precision_score(y_test, y_pred, average="weighted"),
            "recall": recall_score(y_test, y_pred, average="weighted"),
        }

        # MLflowì— ë©”íŠ¸ë¦­ ê¸°ë¡
        for metric_name, value in metrics.items():
            mlflow.log_metric(metric_name, value)
            print(f"  â†’ {metric_name.capitalize()}: {value:.4f}")

        # ëª¨ë¸ ê²€ì¦
        if metrics["accuracy"] < 0.85:
            mlflow.set_tag("validation", "failed")
            print("  âš ï¸  ê²½ê³ : ì •í™•ë„ê°€ 85% ë¯¸ë§Œ!")
            print("  â†’ ì¬í›ˆë ¨ ë˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • í•„ìš”")
        else:
            mlflow.set_tag("validation", "passed")
            print("  âœ… ëª¨ë¸ ê²€ì¦ í†µê³¼ (ì •í™•ë„ >= 85%)")

        return metrics

    def register_model_with_mlflow(self, model, params, metrics):
        """MLflow ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡"""

        model_name = "iris-classifier"

        # ëª¨ë¸ ì €ì¥ ë° ë“±ë¡
        mlflow.sklearn.log_model(
            sk_model=model,
            artifact_path="model",
            registered_model_name=model_name,
        )

        # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
        mlflow.set_tags(
            {
                "framework": "scikit-learn",
                "algorithm": "RandomForest",
                "dataset": "iris",
                "feature_count": 4,
                "target_classes": 3,
            }
        )

        print(f"  â†’ ëª¨ë¸ '{model_name}'ë¡œ MLflow ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡")
        print("  â†’ ì‹¤í—˜ ì¶”ì  URL: http://localhost:5000")

        # ë¡œì»¬ íŒŒì¼ë„ ë°±ì—… ì €ì¥ (ê¸°ì¡´ í˜¸í™˜ì„±)
        model_artifact = {
            "model": model,
            "version": datetime.now().strftime("v%Y%m%d-%H%M%S"),
            "metrics": metrics,
            "params": params,
            "mlflow_run_id": mlflow.active_run().info.run_id,
            "feature_names": [
                "sepal_length",
                "sepal_width",
                "petal_length",
                "petal_width",
            ],
            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "target_names": ["setosa", "versicolor", "virginica"],
            "framework": "scikit-learn",
        }

        model_dir = Path("models")
        model_dir.mkdir(exist_ok=True)
        joblib.dump(model_artifact, model_dir / "model.pkl")

        print("  â†’ ë¡œì»¬ ë°±ì—…: models/model.pkl")

    def run_pipeline(self, n_estimators=100, max_depth=5, run_name=None):
        """MLflow ì¶”ì ì´ í¬í•¨ëœ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        with mlflow.start_run(run_name=run_name):
            print("=" * 60)
            print("MLflow ì¶”ì ì´ í¬í•¨ëœ ML Pipeline ì‹œì‘")
            if run_name:
                print(f"Run Name: {run_name}")
            print("=" * 60)

            # 1. Data Pipeline (ë™ì¼)
            print("\n[1/4] ğŸ“Š Data Pipeline")
            X_train, X_test, y_train, y_test = self.data_pipeline()

            # 2. Training Pipeline (MLflow ì¶”ì  ì¶”ê°€)
            print("\n[2/4] ğŸ¤– Training Pipeline with MLflow")
            model, params = self.training_pipeline_with_tracking(
                X_train,
                y_train,
                n_estimators=n_estimators,
                max_depth=max_depth,
            )

            # 3. Evaluation (ë©”íŠ¸ë¦­ ìë™ ê¸°ë¡)
            print("\n[3/4] ğŸ“ˆ Model Evaluation with MLflow")
            metrics = self.evaluate_model_with_tracking(model, X_test, y_test)

            # 4. Model Registry (ìë™ ë²„ì „ ê´€ë¦¬)
            print("\n[4/4] ğŸª MLflow Model Registry")
            self.register_model_with_mlflow(model, params, metrics)

            run_id = mlflow.active_run().info.run_id
            print(f"\nâœ… Pipeline ì™„ë£Œ! MLflow Run ID: {run_id}")
            print("=" * 60)

            return model, metrics


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="MLflow ì¶”ì ì´ í¬í•¨ëœ Iris ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨"
    )
    parser.add_argument(
        "--n-estimators",
        type=int,
        default=100,
        help="RandomForestì˜ n_estimators í•˜ì´í¼íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’: 100)",
    )
    parser.add_argument(
        "--max-depth",
        type=int,
        default=5,
        help="RandomForestì˜ max_depth í•˜ì´í¼íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’: 5)",
    )
    parser.add_argument(
        "--run-name",
        type=str,
        default=None,
        help="MLflow run ì´ë¦„ (ê¸°ë³¸ê°’: ìë™ ìƒì„±)",
    )
    parser.add_argument(
        "--run-all",
        action="store_true",
        help="ì—¬ëŸ¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ìœ¼ë¡œ ìë™ ì‹¤í–‰",
    )

    args = parser.parse_args()

    pipeline = IrisMLPipelineWithMLflow()

    if args.run_all:
        # ì—¬ëŸ¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©ìœ¼ë¡œ ìë™ ì‹¤í–‰
        param_combinations = [
            {"n_estimators": 100, "max_depth": 5, "run_name": "run_001"},
            {"n_estimators": 50, "max_depth": 3, "run_name": "run_002"},
            {"n_estimators": 200, "max_depth": 10, "run_name": "run_003"},
        ]

        print("=" * 60)
        print(f"ì´ {len(param_combinations)}ê°œì˜ ì‹¤í—˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤")
        print("=" * 60)

        for i, params in enumerate(param_combinations, 1):
            print(f"\n{'='*60}")
            print(f"ì‹¤í—˜ {i}/{len(param_combinations)}: {params['run_name']}")
            print(f"{'='*60}")
            pipeline.run_pipeline(
                n_estimators=params["n_estimators"],
                max_depth=params["max_depth"],
                run_name=params["run_name"],
            )

        print("\n" + "=" * 60)
        print("ëª¨ë“  ì‹¤í—˜ ì™„ë£Œ!")
        print("MLflow UIì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”: http://localhost:5000")
        print("=" * 60)
    else:
        # ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰
        pipeline.run_pipeline(
            n_estimators=args.n_estimators,
            max_depth=args.max_depth,
            run_name=args.run_name,
        )
